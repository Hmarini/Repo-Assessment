import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
import cv2
from PIL import Image

# Define your model class
class CustomResNet50(nn.Module):
    def __init__(self, num_classes=2):
        super(CustomResNet50, self).__init__()
        self.conv_base = models.resnet50(pretrained=False)  # pretrained False since we load weights after
        # Freeze parameters if you want (optional, for training only)
        for param in self.conv_base.parameters():
            param.requires_grad = False
        
        # Replace avgpool with AdaptiveAvgPool2d (usually already is)
        self.conv_base.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        
        num_ftrs = self.conv_base.fc.in_features
        self.conv_base.fc = nn.Sequential(
            nn.Linear(num_ftrs, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        if len(x.shape) == 5:
            x = x.view(-1, x.shape[2], x.shape[3], x.shape[4])
        x = self.conv_base(x)
        return x

# Device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# Instantiate model and load weights
model = CustomResNet50(num_classes=2)
model = torch.load('KVmodelcatdog_resnet50.pth', map_location=device)
model = model.to(device)
model.eval()

# Define the image transformations (adapt according to how your model was trained)
val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # standard ImageNet normalization
                         std=[0.229, 0.224, 0.225])
])

# Map output indices to class names
class_names = ['Cat', 'Dog']

def get_prediction_class(output_tensor):
    # output_tensor shape: [1, num_classes]
    _, predicted_idx = torch.max(output_tensor, 1)
    return class_names[predicted_idx.item()]

# OpenCV video capture from USB camera (usually 0)
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("Error: Could not open video stream")
    exit()

while True:
    ret, frame = cap.read()
    if not ret:
        print("Error: Could not read frame")
        break

    # Convert BGR (OpenCV) frame to PIL Image RGB
    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

    # Preprocess frame
    input_tensor = val_transforms(img).unsqueeze(0).to(device)

    # Model inference
    with torch.no_grad():
        output = model(input_tensor)
    pred_class = get_prediction_class(output)

    # Put prediction text on frame
    cv2.putText(frame, f'Prediction: {pred_class}', (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

    # Show frame
    cv2.imshow('Cat vs Dog Classifier', frame)

    # Press 'q' to quit
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
cv2.destroyAllWindows()
